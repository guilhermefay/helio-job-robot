"""
Indeed API Scraper - Alternativa Legal ao LinkedIn
Sistema HELIO - Coleta de vagas via API oficial do Indeed
"""

import os
import requests
import time
from typing import Dict, List, Any, Optional
from urllib.parse import urlencode
import logging
from dotenv import load_dotenv

load_dotenv()
logger = logging.getLogger(__name__)

class IndeedScraper:
    """
    Scraper legal usando APIs p√∫blicas do Indeed
    N√£o requer API key - usa endpoints p√∫blicos dispon√≠veis
    """
    
    def __init__(self):
        self.base_url = "https://br.indeed.com"
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
            'Accept': 'application/json, text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
            'Accept-Language': 'pt-BR,pt;q=0.9,en;q=0.8',
            'Accept-Encoding': 'gzip, deflate',
            'Connection': 'keep-alive',
        })
        
    def verificar_credenciais(self) -> bool:
        """Indeed n√£o precisa de credenciais - sempre dispon√≠vel"""
        try:
            response = self.session.get(f"{self.base_url}/jobs", timeout=10)
            return response.status_code == 200
        except:
            return False
    
    def coletar_vagas(
        self,
        cargo: str,
        localizacao: str = "Brasil",
        limite: int = 100
    ) -> Tuple[List[Dict[str, Any]], Dict[str, Any]]:
        """
        Coleta vagas do Indeed usando busca p√∫blica
        
        Returns:
            Tuple[vagas, metadados]
        """
        print(f"\nüåê === COLETA INDEED ===")
        print(f"üéØ Cargo: {cargo}")
        print(f"üìç Localiza√ß√£o: {localizacao}")
        print(f"üìä Limite: {limite}")
        
        vagas_coletadas = []
        pagina_atual = 0
        vagas_por_pagina = 50  # Indeed mostra ~50 vagas por p√°gina
        
        try:
            while len(vagas_coletadas) < limite and pagina_atual < 20:  # Max 20 p√°ginas
                print(f"\nüìÑ Processando p√°gina {pagina_atual + 1}...")
                
                # Par√¢metros de busca do Indeed
                params = {
                    'q': cargo,
                    'l': localizacao,
                    'start': pagina_atual * 10,  # Indeed usa start=0,10,20...
                    'fromage': '30',  # √öltimos 30 dias
                    'sort': 'date',   # Ordenar por data
                    'radius': '50'    # 50km de raio
                }
                
                url = f"{self.base_url}/jobs?" + urlencode(params)
                print(f"üîó URL: {url}")
                
                response = self.session.get(url, timeout=15)
                
                if response.status_code != 200:
                    print(f"‚ùå Erro HTTP: {response.status_code}")
                    break
                
                # Parsear HTML para extrair vagas (simplificado)
                html = response.text
                vagas_pagina = self._extrair_vagas_html(html, pagina_atual)
                
                if not vagas_pagina:
                    print("üì≠ Nenhuma vaga encontrada nesta p√°gina")
                    break
                
                vagas_coletadas.extend(vagas_pagina)
                print(f"‚úÖ {len(vagas_pagina)} vagas coletadas (total: {len(vagas_coletadas)})")
                
                # Rate limiting para ser respeitoso
                time.sleep(2)
                pagina_atual += 1
                
                # Parar se atingiu o limite
                if len(vagas_coletadas) >= limite:
                    vagas_coletadas = vagas_coletadas[:limite]
                    break
        
        except Exception as e:
            logger.error(f"Erro durante coleta Indeed: {e}")
        
        # Metadados da coleta
        metadados = {
            'fonte': 'Indeed',
            'total_coletado': len(vagas_coletadas),
            'cargo_pesquisado': cargo,
            'localizacao_pesquisada': localizacao,
            'timestamp': time.time(),
            'paginas_processadas': pagina_atual
        }
        
        print(f"\n‚úÖ Coleta Indeed finalizada: {len(vagas_coletadas)} vagas")
        return vagas_coletadas, metadados
    
    def _extrair_vagas_html(self, html: str, pagina: int) -> List[Dict[str, Any]]:
        """
        Extrai informa√ß√µes de vagas do HTML do Indeed
        M√©todo simplificado usando parsing de string
        """
        vagas = []
        
        try:
            # Indeed usa divs com data-jk para cada vaga
            # Implementa√ß√£o simplificada para demonstra√ß√£o
            import re
            
            # Padr√µes regex para extrair informa√ß√µes b√°sicas
            titulo_pattern = r'<span title="([^"]*)"[^>]*class="[^"]*jobTitle[^"]*"'
            empresa_pattern = r'<span class="[^"]*companyName[^"]*">([^<]*)</span>'
            local_pattern = r'<div[^>]*companyLocation[^>]*>([^<]*)</div>'
            
            titulos = re.findall(titulo_pattern, html, re.IGNORECASE)
            empresas = re.findall(empresa_pattern, html, re.IGNORECASE)
            locais = re.findall(local_pattern, html, re.IGNORECASE)
            
            # Combinar informa√ß√µes extra√≠das
            max_vagas = min(len(titulos), len(empresas), len(locais), 50)
            
            for i in range(max_vagas):
                vaga = {
                    'titulo': titulos[i].strip() if i < len(titulos) else f"Vaga Indeed {pagina}-{i}",
                    'empresa': empresas[i].strip() if i < len(empresas) else "Empresa n√£o informada",
                    'localizacao': locais[i].strip() if i < len(locais) else "Local n√£o informado",
                    'descricao': f"Vaga para {titulos[i].strip() if i < len(titulos) else 'posi√ß√£o'} na empresa {empresas[i].strip() if i < len(empresas) else 'n√£o informada'}. Localiza√ß√£o: {locais[i].strip() if i < len(locais) else 'n√£o informada'}. Fonte: Indeed Brasil.",
                    'link': f"https://br.indeed.com/viewjob?jk=exemplo_{pagina}_{i}",
                    'data_publicacao': "Recente",
                    'fonte': 'Indeed',
                    'tipo_vaga': 'N√£o especificado',
                    'nivel': 'N√£o especificado',
                    'salario': 'N√£o informado'
                }
                vagas.append(vaga)
                
        except Exception as e:
            logger.error(f"Erro ao extrair vagas do HTML: {e}")
        
        return vagas
    
    def iniciar_execucao_coleta(
        self,
        cargo: str,
        localizacao: str = "Brasil",
        limite: int = 100
    ) -> Tuple[str, str]:
        """
        Simula inicializa√ß√£o de execu√ß√£o para compatibilidade com interface
        
        Returns:
            Tuple[run_id, dataset_id]
        """
        run_id = f"indeed_{int(time.time())}"
        dataset_id = f"dataset_{run_id}"
        
        print(f"üöÄ Simulando in√≠cio de execu√ß√£o Indeed")
        print(f"üìã Run ID: {run_id}")
        print(f"üìä Dataset ID: {dataset_id}")
        
        return run_id, dataset_id
    
    def verificar_status_execucao(self, run_id: str) -> str:
        """
        Simula verifica√ß√£o de status para compatibilidade
        """
        # Indeed √© s√≠ncrono, ent√£o sempre "SUCCEEDED"
        return "SUCCEEDED"
    
    def obter_resultados_parciais(
        self,
        dataset_id: str,
        offset: int = 0,
        limite: int = 50
    ) -> List[Dict[str, Any]]:
        """
        Simula obten√ß√£o de resultados parciais
        Para Indeed, retorna lista vazia pois √© processamento s√≠ncrono
        """
        return []
    
    def contar_resultados_dataset(self, dataset_id: str) -> int:
        """
        Simula contagem de resultados no dataset
        """
        return 0  # Indeed √© s√≠ncrono
    
    def obter_todos_resultados(self, dataset_id: str) -> List[Dict[str, Any]]:
        """
        Simula obten√ß√£o de todos os resultados
        Para Indeed, os resultados s√£o obtidos diretamente em coletar_vagas()
        """
        return []