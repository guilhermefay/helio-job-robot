"""
Agente 1: ExtraÃ§Ã£o de Palavras-chave (MPC) - Metodologia Carolina Martins

Este agente implementa a Ferramenta MPC (Mapa de Palavras-Chave) mencionada
em mÃºltiplas aulas como prÃ©-requisito para o currÃ­culo meteÃ³rico.

Processo baseado nas transcriÃ§Ãµes:
1. Coleta de 50-100 vagas relevantes da Ã¡rea
2. ExtraÃ§Ã£o automÃ¡tica de palavras-chave
3. CategorizaÃ§Ã£o (comportamental, tÃ©cnica, digital)
4. ValidaÃ§Ã£o no ChatGPT (mencionado na Aula 6)
5. PriorizaÃ§Ã£o por frequÃªncia
6. Output: Guia estruturado para aplicar no currÃ­culo
"""

import re
import json
import asyncio
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any, Tuple
from collections import Counter, defaultdict
from sqlalchemy.orm import Session
from core.models import (
    MapaPalavrasChave, VagaAnalisada, PalavraChave, 
    ProcessamentoMPC, ValidacaoIA, StatusMPC, CategoriaPalavraChave
)
from core.services.ai_validator import AIValidator
from core.services.job_scraper import JobScraper

class MPCCarolinaMartins:
    """
    ImplementaÃ§Ã£o da Ferramenta MPC (Mapa de Palavras-Chave)
    baseada na metodologia Carolina Martins
    """
    
    # ConfiguraÃ§Ãµes da Metodologia Carolina Martins
    MIN_PALAVRAS_FASE1 = 20  # MÃ­nimo de palavras na fase de pesquisa ampla
    TARGET_PALAVRAS_FASE1 = 30  # Alvo ideal de palavras (30-40)
    MAX_PALAVRAS_FASE1 = 40  # MÃ¡ximo recomendado na fase 1
    TOP_PALAVRAS_FASE2 = 10  # Top 10 para priorizaÃ§Ã£o
    PALAVRAS_TITULO_LINKEDIN = 4  # 3-4 palavras fortes no tÃ­tulo
    COMPETENCIAS_LINKEDIN = 50  # Exatamente 50 competÃªncias
    
    def __init__(self, db: Session):
        self.db = db
        self.palavras_base = self._carregar_palavras_base()
        self.stop_words = self._carregar_stop_words()
        self.padroes_limpeza = self._configurar_padroes_limpeza()
        self.ai_validator = AIValidator()
        self.job_scraper = JobScraper()
    
    async def executar_mpc_completo(
        self, 
        area_interesse: str, 
        cargo_objetivo: str,
        segmentos_alvo: List[str] = None,
        usuario_id: int = None,
        total_vagas_desejadas: int = 100  # ParametrizÃ¡vel, default 100
    ) -> Dict[str, Any]:
        """
        Executa processo MPC completo seguindo metodologia Carolina Martins
        COM LOGS DETALHADOS EM TEMPO REAL
        
        Etapas:
        1. ConfiguraÃ§Ã£o inicial
        2. Coleta de vagas
        3. ExtraÃ§Ã£o de palavras-chave
        4. CategorizaÃ§Ã£o automÃ¡tica
        5. ValidaÃ§Ã£o com IA
        6. PriorizaÃ§Ã£o final
        """
        
        # ================================
        # ğŸš€ INÃCIO DO PROCESSO MPC
        # ================================
        print("\n" + "="*80)
        print("ğŸ¯ INICIANDO AGENTE 1 - MAPA DE PALAVRAS-CHAVE (MPC)")
        print("ğŸ“š Metodologia Carolina Martins")
        print("="*80)
        print(f"ğŸ¯ Cargo alvo: {cargo_objetivo}")
        print(f"ğŸ¢ Ãrea: {area_interesse}")
        print(f"ğŸ“ Segmentos: {segmentos_alvo or 'Todos'}")
        print(f"ğŸ‘¤ UsuÃ¡rio: {usuario_id or 'Demo'}")
        
        # Cria registro MPC
        mpc = MapaPalavrasChave(
            usuario_id=usuario_id,
            area_interesse=area_interesse,
            cargo_objetivo=cargo_objetivo,
            segmentos_alvo=segmentos_alvo or [],
            status=StatusMPC.COLETANDO.value
        )
        self.db.add(mpc)
        self.db.commit()
        
        print(f"ğŸ“Š MPC ID: {mpc.id} criado no banco de dados")
        
        resultado = {
            "mpc_id": mpc.id,
            "logs_detalhados": [],
            "configuracao": {
                "area_interesse": area_interesse,
                "cargo_objetivo": cargo_objetivo,
                "segmentos_alvo": segmentos_alvo,
                "meta_vagas": total_vagas_desejadas
            },
            "coleta_vagas": {},
            "extracao_palavras": {},
            "categorizacao": {},
            "validacao_ia": {},
            "priorizacao_final": {},
            "mpc_final": {}
        }
        
        try:
            # ================================
            # ğŸ“ ETAPA 1: COLETA DE VAGAS
            # ================================
            print("\n" + "-"*60)
            print("ğŸ“ ETAPA 1/6: COLETA DE VAGAS")
            print("-"*60)
            print("ğŸ” Coletando vagas reais do mercado...")
            print("ğŸ¯ FONTES PRIORITÃRIAS (Metodologia Carolina Martins):")
            print("   â€¢ 50% LinkedIn Jobs (fonte #1)")
            print("   â€¢ 30% Google Jobs (fonte #2)")  
            print("   â€¢ 20% fontes secundÃ¡rias (Indeed, InfoJobs, Catho)")
            
            mpc.status = StatusMPC.COLETANDO.value
            self.db.commit()
            
            resultado["coleta_vagas"] = await self._coletar_vagas_com_logs(
                mpc, area_interesse, cargo_objetivo, segmentos_alvo, resultado["logs_detalhados"]
            )
            
            print(f"âœ… COLETA CONCLUÃDA: {resultado['coleta_vagas']['total_coletadas']} vagas")
            
            # ================================
            # ğŸ”¤ ETAPA 2: EXTRAÃ‡ÃƒO DE PALAVRAS-CHAVE
            # ================================
            print("\n" + "-"*60)
            print("ğŸ”¤ ETAPA 2/6: EXTRAÃ‡ÃƒO DE PALAVRAS-CHAVE")
            print("-"*60)
            print("ğŸ§  Processando descriÃ§Ãµes das vagas com NLP...")
            print("ğŸ” Identificando termos compostos (ex: 'power bi', 'gestÃ£o de projetos')")
            print("ğŸ§¹ Aplicando filtros de relevÃ¢ncia profissional")
            
            mpc.status = StatusMPC.PROCESSANDO.value
            self.db.commit()
            
            resultado["extracao_palavras"] = await self._extrair_palavras_chave_com_logs(
                mpc, resultado["logs_detalhados"]
            )
            
            print(f"âœ… EXTRAÃ‡ÃƒO CONCLUÃDA: {resultado['extracao_palavras']['palavras_unicas']} palavras Ãºnicas")
            
            # ================================
            # ğŸ·ï¸ ETAPA 3: CATEGORIZAÃ‡ÃƒO
            # ================================
            print("\n" + "-"*60)
            print("ğŸ·ï¸ ETAPA 3/6: CATEGORIZAÃ‡ÃƒO")
            print("-"*60)
            print("ğŸ“‚ Organizando palavras em categorias metodolÃ³gicas:")
            print("   â€¢ Comportamental: soft skills, lideranÃ§a")
            print("   â€¢ TÃ©cnica: conhecimentos especÃ­ficos da Ã¡rea")
            print("   â€¢ Digital: ferramentas, softwares, tecnologias")
            
            resultado["categorizacao"] = await self._categorizar_palavras_chave_com_logs(
                mpc, resultado["logs_detalhados"]
            )
            
            # ================================
            # ğŸ¤– ETAPA 4: VALIDAÃ‡ÃƒO COM IA
            # ================================
            print("\n" + "-"*60)
            print("ğŸ¤– ETAPA 4/6: VALIDAÃ‡ÃƒO COM IA")
            print("-"*60)
            print("ğŸ§  Enviando palavras-chave para validaÃ§Ã£o com IA...")
            print("ğŸ“ Contexto: cargo, Ã¡rea e descriÃ§Ãµes de vagas")
            print("âœ… IA irÃ¡ aprovar/rejeitar e sugerir melhorias")
            
            resultado["validacao_ia"] = await self._validar_com_ia_com_logs(
                mpc, area_interesse, cargo_objetivo, resultado["logs_detalhados"]
            )
            
            # ================================
            # ğŸ“Š ETAPA 5: PRIORIZAÃ‡ÃƒO FINAL
            # ================================
            print("\n" + "-"*60)
            print("ğŸ“Š ETAPA 5/6: PRIORIZAÃ‡ÃƒO FINAL")
            print("-"*60)
            print("ğŸ¯ Aplicando critÃ©rios de priorizaÃ§Ã£o metodolÃ³gica:")
            print("   â€¢ Essenciais: aparecem em 70%+ das vagas")
            print("   â€¢ Importantes: aparecem em 40-69% das vagas")
            print("   â€¢ Complementares: aparecem em <40% das vagas")
            
            resultado["priorizacao_final"] = await self._priorizar_palavras_chave_com_logs(
                mpc, resultado["logs_detalhados"]
            )
            
            # ================================
            # ğŸ¯ ETAPA 6: CONSOLIDAÃ‡ÃƒO FINAL
            # ================================
            print("\n" + "-"*60)
            print("ğŸ¯ ETAPA 6/6: CONSOLIDAÃ‡ÃƒO FINAL")
            print("-"*60)
            print("ğŸ“‹ Gerando lista final de palavras-chave")
            print("ğŸ“Š Criando dashboard metodolÃ³gico")
            print("ğŸ’¡ Preparando guia de aplicaÃ§Ã£o")
            
            resultado["mpc_final"] = self._consolidar_mpc_com_logs(mpc, resultado["logs_detalhados"])
            
            # ================================
            # âœ… PROCESSO CONCLUÃDO
            # ================================
            mpc.status = StatusMPC.CONCLUIDO.value
            mpc.data_ultima_coleta = datetime.utcnow()
            self.db.commit()
            
            print("\n" + "="*80)
            print("ğŸ‰ AGENTE 1 CONCLUÃDO COM SUCESSO!")
            print("="*80)
            print(f"ğŸ“Š Total de vagas analisadas: {resultado['coleta_vagas']['total_coletadas']}")
            print(f"ğŸ”¤ Palavras-chave extraÃ­das: {resultado['extracao_palavras']['palavras_unicas']}")
            print(f"ğŸ¯ Palavras essenciais: {len(resultado['mpc_final'].get('palavras_essenciais', []))}")
            print(f"â­ Palavras importantes: {len(resultado['mpc_final'].get('palavras_importantes', []))}")
            print(f"ğŸ’¡ Palavras complementares: {len(resultado['mpc_final'].get('palavras_complementares', []))}")
            
            # RESULTADO FINAL DETALHADO
            print("\nğŸ’¡ Quer ver o resultado final estruturado? (s/n): ", end="")
            try:
                mostrar_resultado = True  # ConfigurÃ¡vel
                
                if mostrar_resultado:
                    print("SIM")
                    self._exibir_resultado_final_detalhado(resultado)
                else:
                    print("NÃƒO")
                    print("   âœ… Resultado completo disponÃ­vel no dashboard")
            except:
                print("   âš ï¸ Resultado completo disponÃ­vel no dashboard")
            
            print("="*80)
            
            return resultado
            
        except Exception as e:
            print(f"\nâŒ ERRO NO AGENTE 1: {str(e)}")
            print("ğŸ“ Salvando log de erro...")
            
            mpc.status = StatusMPC.ERRO.value
            self.db.commit()
            
            # Log do erro
            log_erro = ProcessamentoMPC(
                mpc_id=mpc.id,
                etapa="execucao_completa",
                status="erro",
                erro=str(e)
            )
            self.db.add(log_erro)
            self.db.commit()
            
            resultado["logs_detalhados"].append({
                "timestamp": datetime.now().isoformat(),
                "etapa": "erro_critico",
                "status": "erro",
                "detalhes": str(e)
            })
            
            raise e
    
    async def _coletar_vagas_com_logs(
        self, 
        mpc: MapaPalavrasChave, 
        area: str, 
        cargo: str, 
        segmentos: List[str],
        logs: List[Dict]
    ) -> Dict[str, Any]:
        """
        Coleta vagas com logs detalhados em tempo real
        """
        print("ğŸ” Iniciando coleta de vagas...")
        logs.append({
            "timestamp": datetime.now().isoformat(),
            "etapa": "coleta_inicio",
            "status": "executando",
            "detalhes": f"Cargo: {cargo}, Ãrea: {area}"
        })
        
        # Usa o mÃ©todo original mas com logs adicionais
        resultado = await self._coletar_vagas(mpc, area, cargo, segmentos)
        
        print("ğŸ“Š Salvando vagas no banco de dados...")
        
        # OPÃ‡ÃƒO INTERATIVA: Mostrar vagas coletadas
        print(f"\nğŸ’¡ {resultado['total_coletadas']} vagas coletadas!")
        print("   ğŸ“‹ Quer ver as vagas coletadas? (s/n): ", end="")
        
        try:
            # Em ambiente de produÃ§Ã£o, isso viria da interface
            # Por ora, simula que o usuÃ¡rio quer ver algumas vagas
            mostrar_vagas = True  # Pode ser configurÃ¡vel
            
            if mostrar_vagas:
                print("SIM")
                print("\n" + "="*60)
                print("ğŸ“‹ VAGAS COLETADAS - PRIMEIRAS 5 PARA VERIFICAÃ‡ÃƒO")
                print("="*60)
                
                # Busca primeiras vagas para mostrar
                vagas_exemplo = self.db.query(VagaAnalisada)\
                    .filter(VagaAnalisada.mpc_id == mpc.id)\
                    .limit(5)\
                    .all()
                
                for i, vaga in enumerate(vagas_exemplo, 1):
                    print(f"\nğŸ“„ VAGA {i}:")
                    print(f"   ğŸ¢ Empresa: {vaga.empresa}")
                    print(f"   ğŸ“‹ TÃ­tulo: {vaga.titulo}")
                    print(f"   ğŸ“ Local: {vaga.localizacao}")
                    print(f"   ğŸŒ Fonte: {vaga.fonte}")
                    print(f"   ğŸ“ DescriÃ§Ã£o: {vaga.descricao[:200]}...")
                    if vaga.url_original:
                        print(f"   ğŸ”— URL: {vaga.url_original}")
                
                print(f"\nâœ… Total coletado: {resultado['total_coletadas']} vagas")
                print("   ğŸ’¡ Para ver todas as vagas, consulte o relatÃ³rio final")
                print("="*60)
                
                # Adiciona vagas aos logs para inspeÃ§Ã£o posterior
                logs.append({
                    "timestamp": datetime.now().isoformat(),
                    "etapa": "vagas_detalhadas",
                    "status": "info",
                    "detalhes": "Primeiras 5 vagas coletadas",
                    "vagas_exemplo": [
                        {
                            "empresa": vaga.empresa,
                            "titulo": vaga.titulo,
                            "fonte": vaga.fonte,
                            "url": vaga.url_original
                        } for vaga in vagas_exemplo
                    ]
                })
            else:
                print("NÃƒO")
                print("   âœ… Vagas salvas no banco - disponÃ­veis no relatÃ³rio final")
        
        except Exception as e:
            print("   âš ï¸ Erro ao exibir vagas:", e)
        
        # EstatÃ­sticas por fonte
        print(f"\nğŸ“Š BREAKDOWN POR FONTE:")
        fontes_stats = resultado.get('breakdown_fontes', {})
        if isinstance(fontes_stats, dict):
            for fonte, quantidade in fontes_stats.items():
                print(f"   â€¢ {fonte}: {quantidade} vagas")
        else:
            print("   â€¢ EstatÃ­sticas detalhadas disponÃ­veis no relatÃ³rio")
        
        logs.append({
            "timestamp": datetime.now().isoformat(),
            "etapa": "coleta_finalizada",
            "status": "concluido",
            "detalhes": f"Total: {resultado['total_coletadas']} vagas",
            "breakdown_fontes": resultado.get('fontes_reais_utilizadas', []),
            "qualidade_coleta": resultado.get('qualidade_coleta', 'adequada')
        })
        
        return resultado
    
    async def _extrair_palavras_chave_com_logs(
        self, 
        mpc: MapaPalavrasChave,
        logs: List[Dict]
    ) -> Dict[str, Any]:
        """
        ExtraÃ§Ã£o de palavras-chave com logs detalhados
        """
        print("ğŸ”¤ Processando descriÃ§Ãµes das vagas...")
        
        # Busca todas as vagas do MPC
        vagas = self.db.query(VagaAnalisada).filter(VagaAnalisada.mpc_id == mpc.id).all()
        print(f"ğŸ“„ Encontradas {len(vagas)} vagas para processar")
        
        logs.append({
            "timestamp": datetime.now().isoformat(),
            "etapa": "extracao_inicio",
            "status": "executando",
            "detalhes": f"Processando {len(vagas)} vagas"
        })
        
        todas_palavras = []
        vagas_processadas = 0
        palavras_por_vaga = []
        
        for i, vaga in enumerate(vagas):
            if i % 10 == 0:  # Log a cada 10 vagas
                print(f"   ğŸ“ Processando vaga {i+1}/{len(vagas)}: {vaga.empresa}")
            
            # Combina descriÃ§Ã£o e requisitos
            texto_completo = f"{vaga.descricao} {vaga.requisitos}".lower()
            
            # Extrai palavras-chave com mÃ©todo aprimorado
            palavras_vaga = self._extrair_palavras_texto_detalhado(texto_completo)
            palavras_por_vaga.append(len(palavras_vaga))
            
            # Log detalhado das primeiras 3 vagas
            if i < 3:
                print(f"     ğŸ” Vaga {vaga.empresa}: {len(palavras_vaga)} palavras extraÃ­das")
                print(f"     ğŸ“‹ Primeiras palavras: {palavras_vaga[:5]}")
            
            # Salva palavras da vaga
            vaga.palavras_extraidas = palavras_vaga
            vaga.processada = True
            
            todas_palavras.extend(palavras_vaga)
            vagas_processadas += 1
        
        self.db.commit()
        
        # Conta frequÃªncias
        contador_palavras = Counter(todas_palavras)
        total_palavras_unicas = len(contador_palavras)
        
        print(f"ğŸ“Š EstatÃ­sticas de extraÃ§Ã£o:")
        print(f"   â€¢ Total de palavras extraÃ­das: {len(todas_palavras)}")
        print(f"   â€¢ Palavras Ãºnicas: {total_palavras_unicas}")
        print(f"   â€¢ MÃ©dia por vaga: {sum(palavras_por_vaga)/len(palavras_por_vaga):.1f}")
        print(f"   â€¢ Top 5 palavras: {[f'{palavra}({freq})' for palavra, freq in contador_palavras.most_common(5)]}")
        
        # OPÃ‡ÃƒO INTERATIVA: Mostrar palavras-chave extraÃ­das
        print(f"\nğŸ’¡ {total_palavras_unicas} palavras-chave Ãºnicas extraÃ­das!")
        print("   ğŸ“‹ Quer ver a lista de palavras-chave? (s/n): ", end="")
        
        try:
            mostrar_palavras = True  # ConfigurÃ¡vel
            
            if mostrar_palavras:
                print("SIM")
                print("\n" + "="*60)
                print("ğŸ”¤ PALAVRAS-CHAVE EXTRAÃDAS - TOP 20 MAIS FREQUENTES")
                print("="*60)
                
                for i, (palavra, freq) in enumerate(contador_palavras.most_common(20), 1):
                    # Calcula frequÃªncia relativa
                    freq_rel = (freq / len(vagas)) * 100
                    print(f"{i:2d}. {palavra:<25} | {freq:3d}x | {freq_rel:5.1f}% das vagas")
                
                print(f"\nâœ… Total: {total_palavras_unicas} palavras Ãºnicas")
                print("   ğŸ’¡ Lista completa disponÃ­vel no relatÃ³rio final")
                print("="*60)
                
                # Mostra algumas palavras por categoria se jÃ¡ categorizadas
                print("\nğŸ·ï¸ PRÃ‰VIA DAS CATEGORIAS:")
                
                # CategorizaÃ§Ã£o bÃ¡sica para prÃ©via
                palavras_comportamentais = []
                palavras_tecnicas = []
                palavras_digitais = []
                
                for palavra, _ in contador_palavras.most_common(50):
                    categoria = self._determinar_categoria_palavra(palavra)
                    if categoria == "comportamental" and len(palavras_comportamentais) < 5:
                        palavras_comportamentais.append(palavra)
                    elif categoria == "digital" and len(palavras_digitais) < 5:
                        palavras_digitais.append(palavra)
                    elif categoria == "tecnica" and len(palavras_tecnicas) < 5:
                        palavras_tecnicas.append(palavra)
                
                if palavras_comportamentais:
                    print(f"   ğŸ¤ Comportamentais: {', '.join(palavras_comportamentais)}")
                if palavras_digitais:
                    print(f"   ğŸ’» Digitais: {', '.join(palavras_digitais)}")
                if palavras_tecnicas:
                    print(f"   ğŸ”§ TÃ©cnicas: {', '.join(palavras_tecnicas)}")
                
            else:
                print("NÃƒO")
                print("   âœ… Palavras-chave salvas - disponÃ­veis no relatÃ³rio final")
        
        except Exception as e:
            print("   âš ï¸ Erro ao exibir palavras-chave:", e)
        
        # Atualiza MPC
        mpc.total_palavras_extraidas = total_palavras_unicas
        self.db.commit()
        
        logs.append({
            "timestamp": datetime.now().isoformat(),
            "etapa": "extracao_finalizada",
            "status": "concluido",
            "detalhes": {
                "vagas_processadas": vagas_processadas,
                "palavras_totais": len(todas_palavras),
                "palavras_unicas": total_palavras_unicas,
                "top_palavras": contador_palavras.most_common(10)
            }
        })
        
        return {
            "vagas_processadas": vagas_processadas,
            "palavras_unicas": total_palavras_unicas,
            "palavras_mais_frequentes": contador_palavras.most_common(20),
            "qualidade_extracao": self._avaliar_qualidade_extracao(contador_palavras),
            "estatisticas_detalhadas": {
                "palavras_totais": len(todas_palavras),
                "media_por_vaga": sum(palavras_por_vaga)/len(palavras_por_vaga) if palavras_por_vaga else 0
            }
        }
    
    async def _categorizar_palavras_chave_com_logs(
        self, 
        mpc: MapaPalavrasChave,
        logs: List[Dict]
    ) -> Dict[str, Any]:
        """
        CategorizaÃ§Ã£o com logs detalhados
        """
        print("ğŸ·ï¸ Categorizando palavras-chave...")
        
        logs.append({
            "timestamp": datetime.now().isoformat(),
            "etapa": "categorizacao_inicio",
            "status": "executando",
            "detalhes": "Aplicando categorizaÃ§Ã£o metodolÃ³gica"
        })
        
        # Usa mÃ©todo original
        resultado = await self._categorizar_palavras_chave(mpc)
        
        # Logs detalhados da categorizaÃ§Ã£o
        total_por_categoria = resultado["total_por_categoria"]
        print(f"ğŸ“‚ CategorizaÃ§Ã£o concluÃ­da:")
        print(f"   â€¢ Comportamentais: {total_por_categoria.get('comportamental', 0)}")
        print(f"   â€¢ TÃ©cnicas: {total_por_categoria.get('tecnica', 0)}")
        print(f"   â€¢ Digitais: {total_por_categoria.get('digital', 0)}")
        
        # Mostra exemplos de cada categoria
        palavras_cat = resultado["palavras_categorizadas"]
        for categoria, palavras in palavras_cat.items():
            if palavras:
                top_3 = [p["termo"] for p in palavras[:3]]
                print(f"     ğŸ“‹ {categoria.title()}: {', '.join(top_3)}...")
        
        logs.append({
            "timestamp": datetime.now().isoformat(),
            "etapa": "categorizacao_finalizada",
            "status": "concluido",
            "detalhes": {
                "total_por_categoria": total_por_categoria,
                "qualidade": resultado["qualidade_categorizacao"]
            }
        })
        
        return resultado
    
    async def _validar_com_ia_com_logs(
        self, 
        mpc: MapaPalavrasChave, 
        area_interesse: str, 
        cargo_objetivo: str,
        logs: List[Dict]
    ) -> Dict[str, Any]:
        """
        ValidaÃ§Ã£o com IA com logs detalhados
        """
        print("ğŸ¤– Preparando validaÃ§Ã£o com IA...")
        
        # Busca top palavras por categoria
        palavras_top = self.db.query(PalavraChave)\
            .filter(PalavraChave.mpc_id == mpc.id)\
            .order_by(PalavraChave.importancia.desc())\
            .limit(50)\
            .all()
        
        print(f"ğŸ“¤ Enviando {len(palavras_top)} palavras para IA")
        
        # Prepara dados para validaÃ§Ã£o
        palavras_por_categoria = defaultdict(list)
        for palavra in palavras_top:
            palavras_por_categoria[palavra.categoria].append(palavra.termo)
        
        print(f"ğŸ“Š Breakdown para IA:")
        for categoria, termos in palavras_por_categoria.items():
            print(f"   â€¢ {categoria}: {len(termos)} termos")
        
        logs.append({
            "timestamp": datetime.now().isoformat(),
            "etapa": "validacao_ia_inicio",
            "status": "executando",
            "detalhes": {
                "palavras_enviadas": len(palavras_top),
                "breakdown_categorias": {cat: len(termos) for cat, termos in palavras_por_categoria.items()}
            }
        })
        
        # Busca vagas para contexto da validaÃ§Ã£o
        vagas_contexto = self.db.query(VagaAnalisada)\
            .filter(VagaAnalisada.mpc_id == mpc.id)\
            .limit(5)\
            .all()
        
        vagas_dict = [{"descricao": vaga.descricao} for vaga in vagas_contexto]
        
        print("ğŸ§  Chamando IA para validaÃ§Ã£o...")
        print(f"ğŸ“ Contexto: {len(vagas_dict)} descriÃ§Ãµes de vagas")
        print(f"ğŸ¯ Cargo: {cargo_objetivo}")
        print(f"ğŸ¢ Ãrea: {area_interesse}")
        
        # ValidaÃ§Ã£o REAL com IA
        try:
            validacao_resultado = await self._validar_com_ia_real(
                palavras_por_categoria, area_interesse, cargo_objetivo, vagas_dict
            )
            
            print("âœ… IA respondeu com sucesso!")
            print(f"âœ… Aprovadas: {len(validacao_resultado.get('aprovadas', []))}")
            print(f"âŒ Rejeitadas: {len(validacao_resultado.get('rejeitadas', []))}")
            print(f"ğŸ’¡ SugestÃµes: {len(validacao_resultado.get('sugestoes', []))}")
            
            # Mostra exemplos da resposta da IA
            if validacao_resultado.get('aprovadas'):
                print(f"     âœ… Exemplos aprovados: {validacao_resultado['aprovadas'][:3]}")
            if validacao_resultado.get('rejeitadas'):
                print(f"     âŒ Exemplos rejeitados: {validacao_resultado['rejeitadas'][:3]}")
            if validacao_resultado.get('sugestoes'):
                print(f"     ğŸ’¡ SugestÃµes da IA: {validacao_resultado['sugestoes'][:2]}")
            
        except Exception as e:
            print(f"âš ï¸ Erro na validaÃ§Ã£o IA: {e}")
            validacao_resultado = {
                "aprovadas": [p.termo for p in palavras_top[:20]],  # Fallback
                "rejeitadas": [],
                "sugestoes": [],
                "erro": str(e)
            }
        
        # Salva resultado da validaÃ§Ã£o
        validacao_ia = ValidacaoIA(
            mpc_id=mpc.id,
            modelo_ia="gpt-4",
            prompt_utilizado=validacao_resultado.get("prompt_usado", ""),
            palavras_aprovadas=validacao_resultado["aprovadas"],
            palavras_rejeitadas=validacao_resultado["rejeitadas"],
            sugestoes_adicionais=validacao_resultado["sugestoes"],
            confianca=validacao_resultado.get("confianca", 0.8)
        )
        self.db.add(validacao_ia)
        
        # Marca palavras como validadas
        for palavra in palavras_top:
            if palavra.termo in validacao_resultado["aprovadas"]:
                palavra.validada_ia = True
                palavra.recomendada_ia = True
            elif palavra.termo in validacao_resultado["rejeitadas"]:
                palavra.validada_ia = True
                palavra.recomendada_ia = False
        
        # Marca MPC como validado
        mpc.validado_ia = True
        mpc.sugestoes_ia = validacao_resultado["sugestoes"]
        
        self.db.commit()
        
        logs.append({
            "timestamp": datetime.now().isoformat(),
            "etapa": "validacao_ia_finalizada",
            "status": "concluido",
            "detalhes": {
                "aprovadas": len(validacao_resultado["aprovadas"]),
                "rejeitadas": len(validacao_resultado["rejeitadas"]),
                "sugestoes": len(validacao_resultado["sugestoes"]),
                "modelo_usado": validacao_resultado.get("modelo_usado", "ai_real"),
                "confianca": validacao_resultado.get("confianca", 0.8)
            }
        })
        
        return validacao_resultado
    
    async def _priorizar_palavras_chave_com_logs(
        self, 
        mpc: MapaPalavrasChave,
        logs: List[Dict]
    ) -> Dict[str, Any]:
        """
        PriorizaÃ§Ã£o com logs detalhados
        """
        print("ğŸ“Š Aplicando critÃ©rios de priorizaÃ§Ã£o...")
        
        logs.append({
            "timestamp": datetime.now().isoformat(),
            "etapa": "priorizacao_inicio",
            "status": "executando",
            "detalhes": "Aplicando critÃ©rios metodolÃ³gicos"
        })
        
        # Usa mÃ©todo original
        resultado = await self._priorizar_palavras_chave(mpc)
        
        # Logs detalhados da priorizaÃ§Ã£o
        priorizacao = resultado["priorizacao"]
        print(f"ğŸ¯ PriorizaÃ§Ã£o concluÃ­da:")
        print(f"   â€¢ Essenciais (70%+): {len(priorizacao['essenciais'])}")
        print(f"   â€¢ Importantes (40-69%): {len(priorizacao['importantes'])}")
        print(f"   â€¢ Complementares (<40%): {len(priorizacao['complementares'])}")
        
        # Mostra exemplos de cada prioridade
        if priorizacao['essenciais']:
            print(f"     ğŸ”¥ Essenciais: {[p['termo'] for p in priorizacao['essenciais'][:3]]}")
        if priorizacao['importantes']:
            print(f"     â­ Importantes: {[p['termo'] for p in priorizacao['importantes'][:3]]}")
        
        logs.append({
            "timestamp": datetime.now().isoformat(),
            "etapa": "priorizacao_finalizada",
            "status": "concluido",
            "detalhes": {
                "essenciais": len(priorizacao['essenciais']),
                "importantes": len(priorizacao['importantes']),
                "complementares": len(priorizacao['complementares'])
            }
        })
        
        return resultado
    
    def _consolidar_mpc_com_logs(
        self, 
        mpc: MapaPalavrasChave,
        logs: List[Dict]
    ) -> Dict[str, Any]:
        """
        ConsolidaÃ§Ã£o final com logs detalhados
        """
        print("ğŸ¯ Consolidando resultado final...")
        
        logs.append({
            "timestamp": datetime.now().isoformat(),
            "etapa": "consolidacao_inicio",
            "status": "executando",
            "detalhes": "Gerando MPC final"
        })
        
        # Usa mÃ©todo original
        resultado = self._consolidar_mpc(mpc)
        
        print("ğŸ“‹ Resultado final:")
        print(f"   â€¢ Score de qualidade: {resultado['estatisticas']['score_qualidade']:.1f}%")
        print(f"   â€¢ Palavras essenciais: {len(resultado['palavras_essenciais'])}")
        print(f"   â€¢ Palavras importantes: {len(resultado['palavras_importantes'])}")
        print(f"   â€¢ Palavras complementares: {len(resultado['palavras_complementares'])}")
        
        logs.append({
            "timestamp": datetime.now().isoformat(),
            "etapa": "consolidacao_finalizada",
            "status": "concluido",
            "detalhes": {
                "score_qualidade": resultado['estatisticas']['score_qualidade'],
                "total_essenciais": len(resultado['palavras_essenciais']),
                "total_importantes": len(resultado['palavras_importantes']),
                "total_complementares": len(resultado['palavras_complementares'])
            }
        })
        
        return resultado
    
    def _exibir_resultado_final_detalhado(self, resultado: Dict[str, Any]):
        """
        Exibe resultado final estruturado conforme metodologia Carolina Martins
        """
        mpc_final = resultado.get('mpc_final', {})
        
        print("\n" + "ğŸ¯" + "="*78 + "ğŸ¯")
        print("ğŸ“‹ LISTA DE PALAVRAS-CHAVE PERSONALIZADA - METODOLOGIA CAROLINA MARTINS")
        print("ğŸ¯" + "="*78 + "ğŸ¯")
        
        # ConfiguraÃ§Ã£o
        config = resultado.get('configuracao', {})
        print(f"ğŸ¯ CARGO ALVO: {config.get('cargo_objetivo', 'N/A')}")
        print(f"ğŸ¢ ÃREA: {config.get('area_interesse', 'N/A')}")
        print(f"ğŸ“Š BASEADO EM: {resultado['coleta_vagas'].get('total_coletadas', 0)} vagas reais")
        
        # Score de qualidade
        score = mpc_final.get('estatisticas', {}).get('score_qualidade', 0)
        print(f"â­ SCORE DE QUALIDADE: {score:.1f}%")
        
        print("\n" + "ğŸ”¥" + "="*58 + "ğŸ”¥")
        print("ğŸ”¥ PALAVRAS-CHAVE ESSENCIAIS (aparecem em 70%+ das vagas)")
        print("ğŸ”¥" + "="*58 + "ğŸ”¥")
        
        essenciais = mpc_final.get('palavras_essenciais', [])
        if essenciais:
            print("ğŸ’¡ USE ESTAS NO RESUMO PROFISSIONAL E TÃTULO DO LINKEDIN:")
            for i, palavra in enumerate(essenciais, 1):
                freq = palavra.get('frequencia', 0) * 100
                print(f"   {i:2d}. {palavra['termo']:<25} ({freq:5.1f}% das vagas)")
        else:
            print("   âš ï¸ Nenhuma palavra essencial identificada")
        
        print("\n" + "â­" + "="*58 + "â­")
        print("â­ PALAVRAS-CHAVE IMPORTANTES (aparecem em 40-69% das vagas)")
        print("â­" + "="*58 + "â­")
        
        importantes = mpc_final.get('palavras_importantes', [])
        if importantes:
            print("ğŸ’¡ USE ESTAS NAS EXPERIÃŠNCIAS PROFISSIONAIS:")
            for i, palavra in enumerate(importantes, 1):
                freq = palavra.get('frequencia', 0) * 100
                print(f"   {i:2d}. {palavra['termo']:<25} ({freq:5.1f}% das vagas)")
        else:
            print("   âš ï¸ Nenhuma palavra importante identificada")
        
        print("\n" + "ğŸ’¡" + "="*58 + "ğŸ’¡")
        print("ğŸ’¡ PALAVRAS-CHAVE COMPLEMENTARES (aparecem em <40% das vagas)")
        print("ğŸ’¡" + "="*58 + "ğŸ’¡")
        
        complementares = mpc_final.get('palavras_complementares', [])
        if complementares:
            print("ğŸ’¡ USE PARA PERSONALIZAR CADA VAGA ESPECÃFICA:")
            for i, palavra in enumerate(complementares[:10], 1):  # Top 10
                freq = palavra.get('frequencia', 0) * 100
                print(f"   {i:2d}. {palavra['termo']:<25} ({freq:5.1f}% das vagas)")
            if len(complementares) > 10:
                print(f"   ... e mais {len(complementares) - 10} palavras complementares")
        else:
            print("   âš ï¸ Nenhuma palavra complementar identificada")
        
        # Guia de aplicaÃ§Ã£o
        guia = mpc_final.get('guia_aplicacao', {})
        if guia:
            print("\n" + "ğŸ“‹" + "="*58 + "ğŸ“‹")
            print("ğŸ“‹ GUIA PRÃTICO DE APLICAÃ‡ÃƒO")
            print("ğŸ“‹" + "="*58 + "ğŸ“‹")
            
            # Resumo profissional
            resumo_info = guia.get('resumo_profissional', {})
            if resumo_info:
                print("\nğŸ¯ NO RESUMO PROFISSIONAL (obrigatÃ³rio):")
                obrigatorias = resumo_info.get('incluir_obrigatoriamente', [])
                if obrigatorias:
                    print(f"   â€¢ Incluir: {', '.join(obrigatorias[:5])}")
                
                preferenciais = resumo_info.get('incluir_preferencialmente', [])
                if preferenciais:
                    print(f"   â€¢ Preferencial: {', '.join(preferenciais[:3])}")
            
            # ExperiÃªncias
            exp_info = guia.get('experiencias_profissionais', {})
            if exp_info:
                print("\nğŸ’¼ NAS EXPERIÃŠNCIAS PROFISSIONAIS:")
                distribuir = exp_info.get('distribuir_por_experiencia', [])
                if distribuir:
                    print(f"   â€¢ Distribuir: {', '.join(distribuir[:8])}")
            
            # CompetÃªncias
            comp_info = guia.get('competencias', {})
            if comp_info:
                print("\nğŸ› ï¸ NA SEÃ‡ÃƒO COMPETÃŠNCIAS:")
                explicitas = comp_info.get('listar_explicitamente', [])
                if explicitas:
                    print(f"   â€¢ Listar: {', '.join(explicitas[:6])}")
        
        # RecomendaÃ§Ãµes da IA
        validacao_ia = resultado.get('validacao_ia', {})
        if validacao_ia.get('sugestoes'):
            print("\n" + "ğŸ¤–" + "="*58 + "ğŸ¤–")
            print("ğŸ¤– SUGESTÃ•ES ADICIONAIS DA IA")
            print("ğŸ¤–" + "="*58 + "ğŸ¤–")
            
            for sugestao in validacao_ia['sugestoes'][:3]:
                print(f"   ğŸ’¡ {sugestao}")
        
        # Dados concretos de fundamentaÃ§Ã£o
        print("\n" + "ğŸ“Š" + "="*58 + "ğŸ“Š")
        print("ğŸ“Š DADOS CONCRETOS DE FUNDAMENTAÃ‡ÃƒO")
        print("ğŸ“Š" + "="*58 + "ğŸ“Š")
        
        coleta_info = resultado.get('coleta_vagas', {})
        print(f"ğŸ“ˆ Baseado em {coleta_info.get('total_coletadas', 0)} vagas reais")
        
        fontes = coleta_info.get('fontes_reais_utilizadas', [])
        if fontes:
            print(f"ğŸŒ Fontes: {', '.join(fontes)}")
        
        print(f"ğŸ¯ Ãrea: {config.get('area_interesse', 'N/A')}")
        print(f"ğŸ“ LocalizaÃ§Ã£o: SÃ£o Paulo, SP")  # Pode ser parametrizado
        
        # ValidaÃ§Ã£o IA
        if validacao_ia:
            aprovadas = len(validacao_ia.get('aprovadas', []))
            total_validadas = aprovadas + len(validacao_ia.get('rejeitadas', []))
            if total_validadas > 0:
                taxa_aprovacao = (aprovadas / total_validadas) * 100
                print(f"ğŸ¤– ValidaÃ§Ã£o IA: {aprovadas}/{total_validadas} aprovadas ({taxa_aprovacao:.1f}%)")
        
        print("\n" + "ğŸ¯" + "="*78 + "ğŸ¯")

    async def _coletar_vagas(
        self, 
        mpc: MapaPalavrasChave, 
        area: str, 
        cargo: str, 
        segmentos: List[str]
    ) -> Dict[str, Any]:
        """
        Coleta vagas de mÃºltiplas fontes para anÃ¡lise
        
        Objetivo Carolina Martins: 50-100 vagas relevantes
        """
        log_coleta = ProcessamentoMPC(
            mpc_id=mpc.id,
            etapa="coleta_vagas",
            status="executando"
        )
        self.db.add(log_coleta)
        self.db.commit()
        
        vagas_coletadas = []
        fontes_utilizadas = ["linkedin", "indeed", "catho", "infojobs"]
        
        # Coleta REAL de vagas usando job scraper APRIMORADO
        print(f"ğŸš€ Iniciando coleta REAL com priorizaÃ§Ã£o metodolÃ³gica...")
        print(f"ğŸ¯ Cargo: {cargo}")
        print(f"ğŸ¢ Ãrea: {area}")
        print(f"ğŸ“Š Meta: 100 vagas (50% LinkedIn + 30% Google Jobs + 20% outras)")
        
        vagas_reais = self.job_scraper.coletar_vagas_multiplas_fontes(
            area_interesse=area,
            cargo_objetivo=cargo,
            localizacao="SÃ£o Paulo, SP",  # Pode ser parametrizado
            total_vagas_desejadas=total_vagas_desejadas
        )
        
        print(f"âœ… Coleta finalizada: {len(vagas_reais)} vagas obtidas")
        
        # Converte formato do scraper para formato do sistema
        for vaga_real in vagas_reais:
            vaga_formatada = {
                "titulo": vaga_real.get("titulo", ""),
                "empresa": vaga_real.get("empresa", ""),
                "localizacao": vaga_real.get("localizacao", ""),
                "descricao": vaga_real.get("descricao", ""),
                "requisitos": vaga_real.get("descricao", ""),  # Requisitos dentro da descriÃ§Ã£o
                "fonte": vaga_real.get("fonte", ""),
                "url": vaga_real.get("url", ""),
                "data_coleta": vaga_real.get("data_coleta", "")
            }
            vagas_coletadas.append(vaga_formatada)
        
        print(f"Coleta real concluÃ­da: {len(vagas_coletadas)} vagas coletadas")
        
        # Salva vagas no banco
        total_salvas = 0
        for vaga_data in vagas_coletadas:
            vaga = VagaAnalisada(
                mpc_id=mpc.id,
                titulo=vaga_data["titulo"],
                empresa=vaga_data.get("empresa", ""),
                localizacao=vaga_data.get("localizacao", ""),
                descricao=vaga_data.get("descricao", ""),
                requisitos=vaga_data.get("requisitos", ""),
                fonte=vaga_data.get("fonte", ""),
                url_original=vaga_data.get("url", "")
            )
            self.db.add(vaga)
            total_salvas += 1
        
        self.db.commit()
        
        # Atualiza estatÃ­sticas do MPC
        mpc.total_vagas_coletadas = total_salvas
        self.db.commit()
        
        # Atualiza log
        log_coleta.status = "concluido"
        log_coleta.vagas_processadas = total_salvas
        self.db.commit()
        
        # Atualiza fontes utilizadas baseado na coleta real
        fontes_reais_utilizadas = list(set([vaga.get("fonte", "") for vaga in vagas_coletadas if vaga.get("fonte")]))
        
        # Conta vagas por fonte
        breakdown_fontes = {}
        for vaga in vagas_coletadas:
            fonte = vaga.get("fonte", "unknown")
            breakdown_fontes[fonte] = breakdown_fontes.get(fonte, 0) + 1
        
        print(f"ğŸ“Š Breakdown de fontes reais:")
        for fonte, count in breakdown_fontes.items():
            print(f"   â€¢ {fonte}: {count} vagas")
        
        return {
            "total_coletadas": total_salvas,
            "fontes_utilizadas": fontes_reais_utilizadas,
            "breakdown_fontes": breakdown_fontes,
            "fontes_planejadas": fontes_utilizadas,
            "meta_atingida": total_salvas >= 50,
            "qualidade_coleta": "boa" if total_salvas >= 100 else "adequada" if total_salvas >= 50 else "insuficiente",
            "coleta_real_ativa": True,
            "observacao": f"Coleta REAL de {total_salvas} vagas com priorizaÃ§Ã£o metodolÃ³gica",
            "fontes_prioritarias_ativas": True
        }
    
    async def _extrair_palavras_chave(self, mpc: MapaPalavrasChave) -> Dict[str, Any]:
        """
        Extrai palavras-chave de todas as vagas coletadas
        
        Processo Carolina Martins:
        1. AnÃ¡lise de descriÃ§Ãµes e requisitos
        2. Limpeza e normalizaÃ§Ã£o
        3. Contagem de frequÃªncia
        4. IdentificaÃ§Ã£o de padrÃµes
        """
        log_extracao = ProcessamentoMPC(
            mpc_id=mpc.id,
            etapa="extracao_palavras",
            status="executando"
        )
        self.db.add(log_extracao)
        self.db.commit()
        
        # Busca todas as vagas do MPC
        vagas = self.db.query(VagaAnalisada).filter(VagaAnalisada.mpc_id == mpc.id).all()
        
        todas_palavras = []
        vagas_processadas = 0
        
        for vaga in vagas:
            # Combina descriÃ§Ã£o e requisitos
            texto_completo = f"{vaga.descricao} {vaga.requisitos}".lower()
            
            # Extrai palavras-chave com mÃ©todo APRIMORADO
            palavras_vaga = self._extrair_palavras_texto_detalhado(texto_completo)
            
            # Salva palavras da vaga
            vaga.palavras_extraidas = palavras_vaga
            vaga.processada = True
            
            todas_palavras.extend(palavras_vaga)
            vagas_processadas += 1
        
        self.db.commit()
        
        # Conta frequÃªncias
        contador_palavras = Counter(todas_palavras)
        total_palavras_unicas = len(contador_palavras)
        
        # Atualiza MPC
        mpc.total_palavras_extraidas = total_palavras_unicas
        self.db.commit()
        
        # Atualiza log
        log_extracao.status = "concluido"
        log_extracao.vagas_processadas = vagas_processadas
        log_extracao.palavras_encontradas = total_palavras_unicas
        self.db.commit()
        
        return {
            "vagas_processadas": vagas_processadas,
            "palavras_unicas": total_palavras_unicas,
            "palavras_mais_frequentes": contador_palavras.most_common(20),
            "qualidade_extracao": self._avaliar_qualidade_extracao(contador_palavras)
        }
    
    def _extrair_palavras_texto_detalhado(self, texto: str) -> List[str]:
        """
        VersÃ£o aprimorada da extraÃ§Ã£o para capturar 30-70 palavras-chave
        MENOS RESTRITIVA que a versÃ£o original
        """
        # Limpeza inicial mais suave
        texto = re.sub(r'[^\w\s]', ' ', texto)
        texto = re.sub(r'\s+', ' ', texto).strip()
        
        # Identifica termos compostos primeiro (EXPANDIDO)
        termos_compostos = self._identificar_termos_compostos_expandido(texto)
        
        # Extrai palavras individuais com filtros mais permissivos
        palavras = []
        for palavra in texto.split():
            palavra_limpa = palavra.strip().lower()
            if (len(palavra_limpa) > 2 and 
                palavra_limpa not in self.stop_words and 
                self._e_palavra_potencialmente_relevante(palavra_limpa)):
                palavras.append(palavra_limpa)
        
        # Combina termos compostos e palavras individuais
        todas_palavras = termos_compostos + palavras
        
        # NormalizaÃ§Ã£o mais permissiva
        palavras_normalizadas = []
        seen = set()
        
        for palavra in todas_palavras:
            palavra_norm = self._normalizar_palavra(palavra)
            if palavra_norm not in seen and len(palavra_norm) > 2:
                palavras_normalizadas.append(palavra_norm)
                seen.add(palavra_norm)
        
        return palavras_normalizadas
    
    def _identificar_termos_compostos_expandido(self, texto: str) -> List[str]:
        """
        VERSÃƒO EXPANDIDA - identifica muito mais termos compostos
        """
        termos_compostos = []
        
        # PadrÃµes de termos compostos EXPANDIDOS por Ã¡rea
        padroes_compostos = [
            # Ferramentas/Software
            r'excel\s+(avanÃ§ado|intermediÃ¡rio|bÃ¡sico)',
            r'power\s+bi',
            r'google\s+(analytics|ads|drive|sheets)',
            r'facebook\s+ads',
            r'linkedin\s+ads',
            r'microsoft\s+(office|teams|project)',
            r'adobe\s+(photoshop|illustrator|premiere)',
            r'sql\s+(server|developer)',
            
            # GestÃ£o e Processos
            r'gestÃ£o\s+de\s+(projetos|equipe|pessoas|processos|mudanÃ§a|conflitos|tempo|qualidade|estoque|custos|riscos)',
            r'anÃ¡lise\s+de\s+(dados|negÃ³cio|mercado|risco|performance|resultado)',
            r'controle\s+de\s+(qualidade|estoque|custos|orÃ§amento|despesas)',
            r'planejamento\s+(estratÃ©gico|financeiro|operacional|comercial)',
            r'desenvolvimento\s+de\s+(produto|negÃ³cio|estratÃ©gia|pessoas)',
            
            # Marketing e Vendas
            r'marketing\s+(digital|online|de\s+conteÃºdo|de\s+relacionamento)',
            r'redes\s+sociais',
            r'content\s+marketing',
            r'inbound\s+marketing',
            r'email\s+marketing',
            r'growth\s+hacking',
            r'customer\s+(success|experience|journey)',
            r'relacionamento\s+com\s+cliente',
            
            # Metodologias
            r'metodologias\s+Ã¡geis',
            r'design\s+thinking',
            r'lean\s+(startup|six\s+sigma)',
            r'business\s+(intelligence|analyst)',
            r'product\s+(management|owner)',
            r'scrum\s+master',
            
            # Soft Skills
            r'trabalho\s+em\s+equipe',
            r'tomada\s+de\s+decisÃ£o',
            r'resoluÃ§Ã£o\s+de\s+(problemas|conflitos)',
            r'comunicaÃ§Ã£o\s+(oral|escrita|interpessoal|assertiva)',
            r'pensamento\s+(analÃ­tico|crÃ­tico|estratÃ©gico)',
            r'inteligÃªncia\s+emocional',
            r'capacidade\s+de\s+(lideranÃ§a|adaptaÃ§Ã£o|aprendizado)',
            
            # Financeiro/ContÃ¡bil
            r'anÃ¡lise\s+financeira',
            r'fluxo\s+de\s+caixa',
            r'demonstraÃ§Ãµes\s+financeiras',
            r'orÃ§amento\s+(anual|empresarial)',
            r'controladoria\s+financeira',
            
            # Tecnologia/IT
            r'desenvolvimento\s+(web|mobile|software)',
            r'banco\s+de\s+dados',
            r'seguranÃ§a\s+da\s+informaÃ§Ã£o',
            r'infraestrutura\s+de\s+ti',
            r'suporte\s+tÃ©cnico',
            
            # RH/GestÃ£o Pessoas
            r'recursos\s+humanos',
            r'gestÃ£o\s+de\s+talentos',
            r'desenvolvimento\s+humano',
            r'clima\s+organizacional',
            r'recrutamento\s+e\s+seleÃ§Ã£o'
        ]
        
        for padrao in padroes_compostos:
            matches = re.finditer(padrao, texto, re.IGNORECASE)
            for match in matches:
                termo_completo = match.group().lower().strip()
                if termo_completo not in termos_compostos:
                    termos_compostos.append(termo_completo)
        
        return termos_compostos
    
    def _e_palavra_potencialmente_relevante(self, palavra: str) -> bool:
        """
        VersÃ£o MENOS RESTRITIVA para capturar mais palavras
        """
        # Filtros bÃ¡sicos
        if len(palavra) < 3:
            return False
        
        if palavra.lower() in self.stop_words:
            return False
        
        # Palavras irrelevantes especÃ­ficas (REDUZIDA)
        irrelevantes_criticas = [
            'empresa', 'oportunidade', 'vaga', 'Ã¡rea', 'profissional'
        ]
        
        if palavra.lower() in irrelevantes_criticas:
            return False
        
        # Aceita nÃºmeros se forem relevantes (anos de experiÃªncia, etc)
        if palavra.isdigit():
            return int(palavra) > 1990 or int(palavra) < 50  # Anos ou experiÃªncia
        
        # Aceita siglas de 3+ caracteres
        if palavra.isupper() and len(palavra) >= 3:
            return True
        
        # Aceita a maioria das outras palavras
        return True

    def _extrair_palavras_texto(self, texto: str) -> List[str]:
        """
        Extrai palavras-chave relevantes de um texto
        
        Aplica:
        - Limpeza de caracteres especiais
        - RemoÃ§Ã£o de stop words
        - IdentificaÃ§Ã£o de termos compostos
        - NormalizaÃ§Ã£o
        """
        # Limpeza inicial
        texto = re.sub(r'[^\w\s]', ' ', texto)
        texto = re.sub(r'\s+', ' ', texto).strip()
        
        # Identifica termos compostos primeiro
        termos_compostos = self._identificar_termos_compostos(texto)
        
        # Extrai palavras individuais
        palavras = [
            palavra.strip() 
            for palavra in texto.split()
            if len(palavra.strip()) > 2 
            and palavra.strip().lower() not in self.stop_words
        ]
        
        # Combina termos compostos e palavras individuais
        todas_palavras = termos_compostos + palavras
        
        # Remove duplicatas e normaliza
        palavras_normalizadas = list(set([
            self._normalizar_palavra(palavra)
            for palavra in todas_palavras
            if self._e_palavra_relevante(palavra)
        ]))
        
        return palavras_normalizadas
    
    def _identificar_termos_compostos(self, texto: str) -> List[str]:
        """
        Identifica termos compostos relevantes para Ã¡rea profissional
        Ex: "gestÃ£o de projetos", "excel avanÃ§ado", "power bi"
        """
        termos_compostos = []
        
        # PadrÃµes de termos compostos conhecidos
        padroes_compostos = [
            r'excel\s+(avanÃ§ado|intermediÃ¡rio|bÃ¡sico)',
            r'power\s+bi',
            r'gestÃ£o\s+de\s+(projetos|equipe|pessoas|processos)',
            r'anÃ¡lise\s+de\s+(dados|negÃ³cio|mercado)',
            r'controle\s+de\s+(qualidade|estoque|custos)',
            r'planejamento\s+(estratÃ©gico|financeiro|operacional)',
            r'relacionamento\s+com\s+cliente',
            r'trabalho\s+em\s+equipe',
            r'tomada\s+de\s+decisÃ£o',
            r'resoluÃ§Ã£o\s+de\s+(problemas|conflitos)',
            r'comunicaÃ§Ã£o\s+(oral|escrita|interpessoal)',
            r'pensamento\s+(analÃ­tico|crÃ­tico|estratÃ©gico)'
        ]
        
        for padrao in padroes_compostos:
            matches = re.findall(padrao, texto, re.IGNORECASE)
            for match in matches:
                if isinstance(match, tuple):
                    termo_completo = re.search(padrao, texto, re.IGNORECASE).group()
                else:
                    termo_completo = match
                termos_compostos.append(termo_completo.lower().strip())
        
        return list(set(termos_compostos))
    
    def _normalizar_palavra(self, palavra: str) -> str:
        """Normaliza palavra removendo acentos e padronizando"""
        import unicodedata
        
        # Remove acentos
        palavra = unicodedata.normalize('NFD', palavra).encode('ascii', 'ignore').decode('ascii')
        
        # Converte para minÃºsculo
        palavra = palavra.lower().strip()
        
        # Aplica normalizaÃ§Ãµes especÃ­ficas
        normalizacoes = {
            'excel': 'excel',
            'powerbi': 'power bi',
            'power-bi': 'power bi',
            'sql': 'sql',
            'crm': 'crm',
            'erp': 'erp',
            'sap': 'sap',
            'lideranca': 'lideranÃ§a',
            'gestao': 'gestÃ£o',
            'analise': 'anÃ¡lise'
        }
        
        return normalizacoes.get(palavra, palavra)
    
    def _e_palavra_relevante(self, palavra: str) -> bool:
        """Verifica se palavra Ã© relevante para contexto profissional"""
        # Filtros de relevÃ¢ncia
        if len(palavra) < 3:
            return False
        
        if palavra.lower() in self.stop_words:
            return False
        
        # Palavras irrelevantes especÃ­ficas
        irrelevantes = [
            'empresa', 'oportunidade', 'vaga', 'profissional', 'area',
            'conhecimento', 'experiencia', 'habilidade', 'competencia',
            'requisito', 'diferencial', 'atividade', 'responsabilidade'
        ]
        
        if palavra.lower() in irrelevantes:
            return False
        
        return True
    
    async def _categorizar_palavras_chave(self, mpc: MapaPalavrasChave) -> Dict[str, Any]:
        """
        Categoriza palavras-chave em: Comportamental, TÃ©cnica, Digital
        baseado na metodologia Carolina Martins
        """
        # Busca todas as palavras extraÃ­das
        vagas = self.db.query(VagaAnalisada).filter(VagaAnalisada.mpc_id == mpc.id).all()
        
        # Coleta todas as palavras com frequÃªncia
        contador_geral = Counter()
        for vaga in vagas:
            if vaga.palavras_extraidas:
                contador_geral.update(vaga.palavras_extraidas)
        
        # Categoriza cada palavra
        palavras_categorizadas = {
            "comportamental": [],
            "tecnica": [],
            "digital": []
        }
        
        # Garante que coletamos pelo menos MIN_PALAVRAS_FASE1 (20) palavras
        # e idealmente TARGET_PALAVRAS_FASE1 (30) conforme metodologia
        palavras_mais_frequentes = contador_geral.most_common(self.MAX_PALAVRAS_FASE1 * 2)  # Pega o dobro para filtrar
        
        palavras_salvas = 0
        for palavra, frequencia in palavras_mais_frequentes:
            # Para nas primeiras MAX_PALAVRAS_FASE1 (40) palavras relevantes
            if palavras_salvas >= self.MAX_PALAVRAS_FASE1:
                break
                
            categoria = self._determinar_categoria_palavra(palavra)
            
            # Calcula frequÃªncia relativa
            freq_relativa = frequencia / mpc.total_vagas_coletadas
            
            # Cria registro de palavra-chave
            palavra_obj = PalavraChave(
                mpc_id=mpc.id,
                termo=palavra,
                categoria=categoria,
                frequencia_absoluta=frequencia,
                frequencia_relativa=freq_relativa,
                importancia=self._calcular_importancia_palavra(palavra, categoria, freq_relativa)
            )
            self.db.add(palavra_obj)
            palavras_salvas += 1
            
            # Adiciona Ã  categoria correspondente
            palavras_categorizadas[categoria].append({
                "termo": palavra,
                "frequencia_absoluta": frequencia,
                "frequencia_relativa": freq_relativa,
                "importancia": palavra_obj.importancia
            })
        
        # Verifica se atingimos o mÃ­nimo da metodologia
        if palavras_salvas < self.MIN_PALAVRAS_FASE1:
            print(f"âš ï¸  AVISO: Apenas {palavras_salvas} palavras encontradas. Metodologia recomenda mÃ­nimo {self.MIN_PALAVRAS_FASE1}")
        
        self.db.commit()
        
        # Ordena por importÃ¢ncia
        for categoria in palavras_categorizadas:
            palavras_categorizadas[categoria].sort(
                key=lambda x: x["importancia"], 
                reverse=True
            )
        
        return {
            "total_por_categoria": {
                cat: len(palavras) for cat, palavras in palavras_categorizadas.items()
            },
            "palavras_categorizadas": palavras_categorizadas,
            "qualidade_categorizacao": self._avaliar_qualidade_categorizacao(palavras_categorizadas)
        }
    
    def _determinar_categoria_palavra(self, palavra: str) -> str:
        """
        Determina categoria da palavra baseado na metodologia Carolina Martins
        
        Categorias:
        - Comportamental: soft skills, competÃªncias interpessoais
        - TÃ©cnica: conhecimentos especÃ­ficos da Ã¡rea, linguagens, frameworks
        - Digital: ferramentas, softwares de produtividade
        """
        palavra_lower = palavra.lower()
        
        # CORREÃ‡ÃƒO: Ferramentas de produtividade e software = DIGITAL
        ferramentas_digitais = [
            'excel', 'power bi', 'tableau', 'word', 'powerpoint', 'access', 
            'outlook', 'teams', 'slack', 'jira', 'confluence', 'trello',
            'asana', 'monday', 'notion', 'figma', 'sketch', 'photoshop',
            'illustrator', 'premiere', 'after effects', 'canva', 'miro',
            'google analytics', 'google ads', 'facebook ads', 'linkedin ads',
            'hubspot', 'mailchimp', 'salesforce', 'pipedrive', 'zendesk'
        ]
        
        if any(tool in palavra_lower for tool in ferramentas_digitais):
            return CategoriaPalavraChave.DIGITAL.value
        
        # CORREÃ‡ÃƒO: Linguagens e frameworks = TÃ‰CNICA
        competencias_tecnicas = [
            'python', 'java', 'javascript', 'typescript', 'c++', 'c#', 'ruby',
            'go', 'rust', 'php', 'swift', 'kotlin', 'scala', 'r', 'matlab',
            'sql', 'nosql', 'mysql', 'postgresql', 'mongodb', 'redis',
            'react', 'angular', 'vue', 'django', 'flask', 'spring', 'rails',
            'node', 'express', '.net', 'aws', 'azure', 'gcp', 'docker',
            'kubernetes', 'terraform', 'jenkins', 'git', 'github', 'gitlab',
            'api', 'rest', 'graphql', 'microservices', 'cloud', 'devops',
            'scrum', 'agile', 'kanban', 'lean', 'six sigma', 'pmbok', 'itil',
            'machine learning', 'deep learning', 'inteligÃªncia artificial',
            'data science', 'analytics', 'bi', 'etl', 'sap', 'oracle', 'erp'
        ]
        
        if any(tech in palavra_lower for tech in competencias_tecnicas):
            return CategoriaPalavraChave.TECNICA.value
        
        # Palavras comportamentais (mantÃ©m como estÃ¡)
        if any(comp in palavra_lower for comp in [
            'lideranÃ§a', 'comunicaÃ§Ã£o', 'trabalho em equipe', 'proatividade',
            'organizaÃ§Ã£o', 'planejamento', 'negociaÃ§Ã£o', 'relacionamento',
            'criatividade', 'inovaÃ§Ã£o', 'adaptabilidade', 'flexibilidade',
            'responsabilidade', 'comprometimento', 'iniciativa', 'empatia',
            'colaboraÃ§Ã£o', 'motivaÃ§Ã£o', 'persuasÃ£o', 'networking',
            'resiliÃªncia', 'foco', 'disciplina', 'Ã©tica', 'integridade'
        ]):
            return CategoriaPalavraChave.COMPORTAMENTAL.value
        
        # Palavras tÃ©cnicas (padrÃ£o para termos especÃ­ficos da Ã¡rea)
        return CategoriaPalavraChave.TECNICA.value
    
    def _calcular_importancia_palavra(
        self, 
        palavra: str, 
        categoria: str, 
        freq_relativa: float
    ) -> float:
        """
        Calcula importÃ¢ncia da palavra baseado em mÃºltiplos fatores
        
        Fatores:
        - FrequÃªncia relativa (50%)
        - Categoria (20%) - digitais tÃªm peso maior
        - Especificidade (20%) - termos mais especÃ­ficos tÃªm peso maior
        - Tamanho (10%) - termos compostos tÃªm peso maior
        """
        score = freq_relativa * 0.5
        
        # Peso por categoria
        if categoria == CategoriaPalavraChave.DIGITAL.value:
            score += 0.2
        elif categoria == CategoriaPalavraChave.COMPORTAMENTAL.value:
            score += 0.15
        else:  # tÃ©cnica
            score += 0.1
        
        # Peso por especificidade (termos compostos sÃ£o mais especÃ­ficos)
        if ' ' in palavra:  # termo composto
            score += 0.2
        elif len(palavra) > 8:  # palavra longa/especÃ­fica
            score += 0.15
        else:
            score += 0.1
        
        # Peso por tamanho
        if len(palavra.split()) > 1:  # termo composto
            score += 0.1
        elif len(palavra) > 6:
            score += 0.08
        else:
            score += 0.05
        
        return min(score, 1.0)
    
    async def _validar_com_ia(
        self, 
        mpc: MapaPalavrasChave, 
        area_interesse: str, 
        cargo_objetivo: str
    ) -> Dict[str, Any]:
        """
        Valida palavras-chave com IA seguindo menÃ§Ã£o da Aula 6
        "ValidaÃ§Ã£o no ChatGPT"
        """
        # Busca top palavras por categoria
        palavras_top = self.db.query(PalavraChave)\
            .filter(PalavraChave.mpc_id == mpc.id)\
            .order_by(PalavraChave.importancia.desc())\
            .limit(50)\
            .all()
        
        # Prepara dados para validaÃ§Ã£o
        palavras_por_categoria = defaultdict(list)
        for palavra in palavras_top:
            palavras_por_categoria[palavra.categoria].append(palavra.termo)
        
        # Busca vagas para contexto da validaÃ§Ã£o
        vagas_contexto = self.db.query(VagaAnalisada)\
            .filter(VagaAnalisada.mpc_id == mpc.id)\
            .limit(5)\
            .all()
        
        vagas_dict = [{"descricao": vaga.descricao} for vaga in vagas_contexto]
        
        # ValidaÃ§Ã£o REAL com IA
        validacao_resultado = await self._validar_com_ia_real(
            palavras_por_categoria, area_interesse, cargo_objetivo, vagas_dict
        )
        
        # Salva resultado da validaÃ§Ã£o
        validacao_ia = ValidacaoIA(
            mpc_id=mpc.id,
            modelo_ia="gpt-4",
            prompt_utilizado=validacao_resultado["prompt_usado"],
            palavras_aprovadas=validacao_resultado["aprovadas"],
            palavras_rejeitadas=validacao_resultado["rejeitadas"],
            sugestoes_adicionais=validacao_resultado["sugestoes"],
            confianca=validacao_resultado["confianca"]
        )
        self.db.add(validacao_ia)
        
        # Marca palavras como validadas
        for palavra in palavras_top:
            if palavra.termo in validacao_resultado["aprovadas"]:
                palavra.validada_ia = True
                palavra.recomendada_ia = True
            elif palavra.termo in validacao_resultado["rejeitadas"]:
                palavra.validada_ia = True
                palavra.recomendada_ia = False
        
        # Marca MPC como validado
        mpc.validado_ia = True
        mpc.sugestoes_ia = validacao_resultado["sugestoes"]
        
        self.db.commit()
        
        return validacao_resultado
    
    async def _validar_com_ia_real(
        self, 
        palavras_por_categoria: Dict[str, List[str]], 
        area: str, 
        cargo: str,
        vagas_contexto: List[Dict[str, Any]] = None
    ) -> Dict[str, Any]:
        """
        ValidaÃ§Ã£o REAL com IA usando OpenAI/Anthropic
        """
        # Prepara contexto das vagas para melhorar validaÃ§Ã£o
        contexto_vagas = []
        if vagas_contexto:
            for vaga in vagas_contexto[:3]:  # Usa top 3 vagas como contexto
                contexto_vagas.append(vaga.get('descricao', '')[:200])
        
        # Chama validador real
        validacao_resultado = await self.ai_validator.validar_palavras_chave(
            palavras_por_categoria=palavras_por_categoria,
            area=area,
            cargo=cargo,
            contexto_vagas=contexto_vagas
        )
        
        # Converte formato para compatibilidade
        aprovadas = validacao_resultado.get('aprovadas', [])
        rejeitadas_com_motivo = validacao_resultado.get('rejeitadas', [])
        
        # Extrai apenas as palavras rejeitadas para compatibilidade
        rejeitadas = []
        if isinstance(rejeitadas_com_motivo, list):
            for item in rejeitadas_com_motivo:
                if isinstance(item, dict):
                    rejeitadas.append(item.get('palavra', ''))
                else:
                    rejeitadas.append(str(item))
        
        # Monta resultado final
        resultado = {
            "aprovadas": aprovadas,
            "rejeitadas": rejeitadas,
            "rejeitadas_detalhadas": rejeitadas_com_motivo,
            "sugestoes": validacao_resultado.get('sugestoes_novas', []),
            "comentarios": validacao_resultado.get('comentarios', ''),
            "confianca": validacao_resultado.get('confianca', 0.8),
            "modelo_usado": validacao_resultado.get('modelo_usado', 'ai_real'),
            "prompt_usado": validacao_resultado.get('prompt_usado', 'ValidaÃ§Ã£o com IA real')
        }
        
        return resultado
    
    async def _priorizar_palavras_chave(self, mpc: MapaPalavrasChave) -> Dict[str, Any]:
        """
        Prioriza palavras-chave seguindo critÃ©rio Carolina Martins
        
        PriorizaÃ§Ã£o:
        - Essenciais: aparecem em 70%+ das vagas
        - Importantes: aparecem em 40-69% das vagas  
        - Complementares: aparecem em menos de 40%
        """
        palavras = self.db.query(PalavraChave)\
            .filter(PalavraChave.mpc_id == mpc.id)\
            .filter(PalavraChave.validada_ia == True)\
            .filter(PalavraChave.recomendada_ia == True)\
            .all()
        
        priorizacao = {
            "essenciais": [],
            "importantes": [],
            "complementares": []
        }
        
        for palavra in palavras:
            freq = palavra.frequencia_relativa
            
            item = {
                "termo": palavra.termo,
                "categoria": palavra.categoria,
                "frequencia": freq,
                "importancia": palavra.importancia
            }
            
            if freq >= 0.7:
                priorizacao["essenciais"].append(item)
            elif freq >= 0.4:
                priorizacao["importantes"].append(item)
            else:
                priorizacao["complementares"].append(item)
        
        # Ordena cada categoria por importÃ¢ncia
        for categoria in priorizacao:
            priorizacao[categoria].sort(key=lambda x: x["importancia"], reverse=True)
        
        # Salva no MPC
        mpc.palavras_chave_priorizadas = {
            "por_prioridade": priorizacao,
            "por_categoria": self._organizar_por_categoria(palavras)
        }
        self.db.commit()
        
        return {
            "priorizacao": priorizacao,
            "total_essenciais": len(priorizacao["essenciais"]),
            "total_importantes": len(priorizacao["importantes"]),
            "total_complementares": len(priorizacao["complementares"]),
            "recomendacao_uso": self._gerar_recomendacao_uso(priorizacao)
        }
    
    def _consolidar_mpc(self, mpc: MapaPalavrasChave) -> Dict[str, Any]:
        """
        Consolida MPC final com todas as informaÃ§Ãµes
        Output: Guia estruturado para aplicar no currÃ­culo
        """
        # Calcula score de qualidade
        score_qualidade = mpc.calcular_score_qualidade()
        
        # Busca dados para consolidaÃ§Ã£o
        priorizacao = mpc.palavras_chave_priorizadas.get("por_prioridade", {})
        
        # Gera TOP 10 palavras conforme Fase 2 da metodologia
        todas_palavras_ordenadas = []
        todas_palavras_ordenadas.extend(priorizacao.get("essenciais", []))
        todas_palavras_ordenadas.extend(priorizacao.get("importantes", []))
        todas_palavras_ordenadas.extend(priorizacao.get("complementares", []))
        
        # Ordena por importÃ¢ncia e pega TOP 10
        todas_palavras_ordenadas.sort(key=lambda x: x["importancia"], reverse=True)
        top_10_metodologia = todas_palavras_ordenadas[:self.TOP_PALAVRAS_FASE2]
        
        mpc_final = {
            "id": mpc.id,
            "configuracao": {
                "area_interesse": mpc.area_interesse,
                "cargo_objetivo": mpc.cargo_objetivo,
                "segmentos_alvo": mpc.segmentos_alvo
            },
            "estatisticas": {
                "total_vagas_analisadas": mpc.total_vagas_coletadas,
                "total_palavras_extraidas": mpc.total_palavras_extraidas,
                "score_qualidade": score_qualidade,
                "validado_ia": mpc.validado_ia,
                "metodologia_carolina_martins": {
                    "fase1_total_palavras": len(todas_palavras_ordenadas),
                    "fase1_alvo_atingido": len(todas_palavras_ordenadas) >= self.MIN_PALAVRAS_FASE1,
                    "fase2_top10": len(top_10_metodologia)
                }
            },
            "palavras_essenciais": priorizacao.get("essenciais", []),
            "palavras_importantes": priorizacao.get("importantes", []),  
            "palavras_complementares": priorizacao.get("complementares", []),
            "top_10_carolina_martins": top_10_metodologia,  # TOP 10 da metodologia
            "guia_aplicacao": self._gerar_guia_aplicacao(priorizacao),
            "recomendacoes": self._gerar_recomendacoes_finais(mpc, score_qualidade)
        }
        
        return mpc_final
    
    def _gerar_guia_aplicacao(self, priorizacao: Dict[str, List[Dict]]) -> Dict[str, Any]:
        """
        Gera guia prÃ¡tico para aplicar palavras-chave no currÃ­culo
        baseado na metodologia Carolina Martins
        """
        essenciais = priorizacao.get("essenciais", [])
        importantes = priorizacao.get("importantes", [])
        
        return {
            "resumo_profissional": {
                "incluir_obrigatoriamente": [p["termo"] for p in essenciais[:5]],
                "incluir_preferencialmente": [p["termo"] for p in importantes[:3]],
                "instrucoes": "Use estas palavras-chave no resumo de forma natural"
            },
            "experiencias_profissionais": {
                "distribuir_por_experiencia": [p["termo"] for p in essenciais + importantes[:5]],
                "instrucoes": "Distribua as palavras-chave nas descriÃ§Ãµes das experiÃªncias"
            },
            "competencias": {
                "listar_explicitamente": [p["termo"] for p in essenciais if p["categoria"] == "digital"],
                "instrucoes": "Liste competÃªncias digitais/tÃ©cnicas explicitamente"
            },
            "personalizacao": {
                "palavras_vaga_especifica": "Use palavras-chave exatas da job description",
                "instrucoes": "Sempre personalize com palavras-chave especÃ­ficas da vaga"
            }
        }
    
    def _gerar_recomendacoes_finais(
        self, 
        mpc: MapaPalavrasChave, 
        score_qualidade: float
    ) -> List[str]:
        """Gera recomendaÃ§Ãµes finais baseadas na qualidade do MPC"""
        recomendacoes = []
        
        if score_qualidade >= 80:
            recomendacoes.append("MPC de alta qualidade - pronto para uso no currÃ­culo")
        elif score_qualidade >= 60:
            recomendacoes.append("MPC de qualidade adequada - considere coletar mais vagas")
        else:
            recomendacoes.append("MPC necessita melhorias - colete mais vagas e refaÃ§a anÃ¡lise")
        
        if mpc.total_vagas_coletadas < 50:
            recomendacoes.append("Recomenda-se coletar pelo menos 50 vagas para maior precisÃ£o")
        
        if not mpc.validado_ia:
            recomendacoes.append("Valide palavras-chave com IA para maior assertividade")
        
        return recomendacoes
    
    # MÃ©todos auxiliares
    
    def _carregar_palavras_base(self) -> Dict[str, List[str]]:
        """Carrega base de palavras-chave por categoria"""
        return {
            "comportamental": [
                "lideranÃ§a", "comunicaÃ§Ã£o", "trabalho em equipe", "proatividade",
                "organizaÃ§Ã£o", "planejamento", "negociaÃ§Ã£o", "relacionamento"
            ],
            "tecnica": [
                "gestÃ£o", "anÃ¡lise", "controle", "desenvolvimento", "implementaÃ§Ã£o",
                "coordenaÃ§Ã£o", "supervisÃ£o", "operaÃ§Ã£o"
            ],
            "digital": [
                "excel", "power bi", "sql", "sap", "crm", "erp", "word",
                "powerpoint", "outlook", "teams"
            ]
        }
    
    def _carregar_stop_words(self) -> List[str]:
        """Carrega lista de stop words em portuguÃªs"""
        return [
            "de", "da", "do", "das", "dos", "e", "em", "para", "com", "por",
            "ser", "ter", "estar", "fazer", "ir", "vir", "dar", "ver",
            "o", "a", "os", "as", "um", "uma", "uns", "umas",
            "que", "qual", "quais", "quando", "onde", "como", "porque",
            "mas", "ou", "se", "entÃ£o", "assim", "tambÃ©m", "ainda",
            "jÃ¡", "nÃ£o", "sim", "muito", "mais", "menos", "bem", "mal"
        ]
    
    def _configurar_padroes_limpeza(self) -> List[str]:
        """Configura padrÃµes regex para limpeza de texto"""
        return [
            r'\b(anos?|meses?|dias?)\b',  # unidades de tempo
            r'\b(r\$|\$|â‚¬|Â£)\s*\d+', # valores monetÃ¡rios
            r'\b\d{1,2}[hH]\d{2}\b',  # horÃ¡rios
            r'\b\d+[kg|km|mÂ²|%]\b'    # unidades de medida
        ]
    
    def _avaliar_qualidade_extracao(self, contador: Counter) -> str:
        """Avalia qualidade da extraÃ§Ã£o baseada nas palavras encontradas"""
        total_palavras = len(contador)
        palavras_relevantes = sum(1 for palavra in contador.keys() if self._e_palavra_relevante(palavra))
        
        proporcao_relevantes = palavras_relevantes / total_palavras if total_palavras > 0 else 0
        
        if proporcao_relevantes >= 0.7:
            return "excelente"
        elif proporcao_relevantes >= 0.5:
            return "boa"
        elif proporcao_relevantes >= 0.3:
            return "adequada"
        else:
            return "insuficiente"
    
    def _avaliar_qualidade_categorizacao(self, palavras_cat: Dict[str, List]) -> str:
        """Avalia distribuiÃ§Ã£o das categorias"""
        total = sum(len(palavras) for palavras in palavras_cat.values())
        
        if total == 0:
            return "insuficiente"
        
        # Verifica se hÃ¡ palavras em todas as categorias
        categorias_com_palavras = sum(1 for palavras in palavras_cat.values() if len(palavras) > 0)
        
        if categorias_com_palavras == 3:
            return "completa"
        elif categorias_com_palavras >= 2:
            return "adequada"
        else:
            return "incompleta"
    
    def _organizar_por_categoria(self, palavras: List[PalavraChave]) -> Dict[str, List[Dict]]:
        """Organiza palavras por categoria"""
        por_categoria = defaultdict(list)
        
        for palavra in palavras:
            if palavra.recomendada_ia:
                por_categoria[palavra.categoria].append({
                    "termo": palavra.termo,
                    "frequencia": palavra.frequencia_relativa,
                    "importancia": palavra.importancia
                })
        
        # Ordena cada categoria
        for categoria in por_categoria:
            por_categoria[categoria].sort(key=lambda x: x["importancia"], reverse=True)
        
        return dict(por_categoria)
    
    def _gerar_recomendacao_uso(self, priorizacao: Dict[str, List]) -> Dict[str, str]:
        """Gera recomendaÃ§Ãµes de uso das palavras-chave"""
        total_essenciais = len(priorizacao.get("essenciais", []))
        total_importantes = len(priorizacao.get("importantes", []))
        
        recomendacoes = {}
        
        if total_essenciais >= 5:
            recomendacoes["essenciais"] = "Use todas as palavras essenciais no resumo e experiÃªncias"
        elif total_essenciais >= 3:
            recomendacoes["essenciais"] = "Use pelo menos 3 palavras essenciais no resumo"
        else:
            recomendacoes["essenciais"] = "Poucas palavras essenciais - revise o MPC"
        
        if total_importantes >= 10:
            recomendacoes["importantes"] = "Distribua palavras importantes nas experiÃªncias"
        else:
            recomendacoes["importantes"] = "Use palavras importantes como complemento"
        
        recomendacoes["geral"] = "Sempre personalize com palavras-chave especÃ­ficas da vaga"
        
        return recomendacoes