#!/usr/bin/env python3
"""
API HELIO - Integra√ß√£o REAL com APIFY LinkedIn Scraper
"""
import os
import sys
import json
import time
import logging
from datetime import datetime
from flask import Flask, request, Response, jsonify
from flask_cors import CORS, cross_origin

# Configurar logging detalhado
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# Adicionar path para os m√≥dulos do projeto
sys.path.insert(0, os.path.join(os.path.dirname(__file__)))

# Importar servi√ßo Google Jobs via APIFY
from core.services.google_jobs_scraper import GoogleJobsScraper

app = Flask(__name__)

# Configura√ß√£o CORS para Vercel
CORS(app, 
     origins=[
         'https://agenteslinkedin.vercel.app',
         'https://helio-job-robot.vercel.app', 
         'https://helio-job-robot-*.vercel.app',
         'http://localhost:3000',
         'http://localhost:3001'
     ], 
     allow_headers=['Content-Type', 'Authorization'], 
     methods=['GET', 'POST', 'OPTIONS', 'PUT', 'DELETE'],
     supports_credentials=True)

@app.after_request
def after_request(response):
    """Adiciona headers CORS em todas as respostas"""
    origin = request.headers.get('Origin')
    allowed_origins = [
        'https://agenteslinkedin.vercel.app',
        'https://helio-job-robot.vercel.app',
        'http://localhost:3000',
        'http://localhost:3001'
    ]
    
    logger.info(f"üåê CORS Debug - Origin: {origin}")
    
    if origin in allowed_origins or (origin and 'helio-job-robot' in origin and 'vercel.app' in origin):
        response.headers['Access-Control-Allow-Origin'] = origin
        response.headers['Access-Control-Allow-Headers'] = 'Content-Type, Authorization'
        response.headers['Access-Control-Allow-Methods'] = 'GET, POST, OPTIONS, PUT, DELETE'
        response.headers['Access-Control-Allow-Credentials'] = 'true'
        logger.info(f"‚úÖ CORS permitido para origem: {origin}")
    else:
        logger.warning(f"‚ùå CORS negado para origem: {origin}")
    
    return response

@app.route('/api/health', methods=['GET'])
@cross_origin()
def health():
    """Health check com status do APIFY"""
    
    apify_token = os.environ.get('APIFY_API_TOKEN')
    apify_status = "configurado" if apify_token else "n√£o configurado"
    
    sistema_status = {
        'status': 'ok',
        'service': 'helio-apify-api',
        'timestamp': datetime.now().isoformat(),
        'versao': '3.0-apify-real',
        'apify_status': apify_status,
        'port': os.environ.get('PORT', '5000')
    }
    
    logger.info(f"üè• Health check OK - APIFY: {apify_status}")
    return jsonify(sistema_status)

@app.route('/api/agent1/collect-keywords', methods=['POST', 'OPTIONS'])
@cross_origin()
def collect_keywords():
    """
    üéØ ENDPOINT REAL PARA COLETA COM APIFY LINKEDIN SCRAPER
    """
    
    if request.method == 'OPTIONS':
        return '', 200
    
    try:
        logger.info("üéØ Iniciando coleta REAL com APIFY LinkedIn Scraper")
        
        # Capturar dados da requisi√ß√£o
        data = request.get_json()
        if not data:
            logger.error("‚ùå Dados n√£o fornecidos na requisi√ß√£o")
            return jsonify({'error': 'Dados n√£o fornecidos na requisi√ß√£o'}), 400
        
        # Extrair par√¢metros
        cargo = data.get('cargo_objetivo', 'Desenvolvedor')
        area = data.get('area_interesse', 'Tecnologia')
        localizacao = data.get('localizacao', 'S√£o Paulo')
        quantidade = data.get('total_vagas_desejadas', 20)
        
        logger.info(f"üìã Par√¢metros: cargo={cargo}, √°rea={area}, local={localizacao}, qtd={quantidade}")
        
        # Verificar token APIFY
        apify_token = os.environ.get('APIFY_API_TOKEN')
        if not apify_token:
            logger.error("‚ùå APIFY_API_TOKEN n√£o configurado!")
            return jsonify({
                'error': 'APIFY_API_TOKEN n√£o configurado',
                'message': 'Configure a vari√°vel de ambiente APIFY_API_TOKEN no Railway'
            }), 500
        
        # Instanciar scraper Google Jobs
        scraper = GoogleJobsScraper()
        
        # Executar coleta
        logger.info("üöÄ Iniciando scraping com Google Jobs...")
        vagas = scraper.coletar_vagas_google(
            cargo=cargo,
            localizacao=localizacao,
            limite=quantidade
        )
        
        # Criar resultado no formato esperado
        resultado_scraping = {
            'vagas': vagas,
            'total_coletadas': len(vagas)
        }
        
        if not resultado_scraping or not resultado_scraping.get('vagas'):
            logger.error("‚ùå Nenhuma vaga coletada pelo APIFY")
            return jsonify({
                'error': 'Nenhuma vaga encontrada',
                'message': 'O APIFY n√£o retornou vagas para os par√¢metros informados'
            }), 404
        
        # Processar resultado
        vagas_processadas = resultado_scraping['vagas']
        total_vagas = len(vagas_processadas)
        
        # Montar resposta final
        resultado = {
            'apify_mode': True,
            'id': f'apify_{int(time.time())}',
            'timestamp': datetime.now().isoformat(),
            'parametros': {
                'area_interesse': area,
                'cargo_objetivo': cargo,
                'localizacao': localizacao,
                'total_vagas_desejadas': quantidade
            },
            'estatisticas': {
                'totalVagas': total_vagas,
                'vagasAnalisadas': total_vagas,
                'successRate': 100 if total_vagas > 0 else 0,
                'tempoColeta': resultado_scraping.get('tempo_execucao', 'N/A')
            },
            'transparencia': {
                'fontes_utilizadas': ['LinkedIn via APIFY'],
                'metodo_coleta': 'APIFY LinkedIn Jobs Scraper',
                'filtros_aplicados': f'Cargo: {cargo}, Localiza√ß√£o: {localizacao}',
                'observacoes': 'Dados reais coletados do LinkedIn via APIFY API',
                'actor_id': resultado_scraping.get('actor_id', 'N/A'),
                'run_id': resultado_scraping.get('run_id', 'N/A')
            },
            'vagas': vagas_processadas
        }
        
        logger.info(f"‚úÖ Coleta APIFY finalizada: {total_vagas} vagas")
        return jsonify(resultado)
        
    except Exception as e:
        logger.error(f"‚ùå Erro na coleta APIFY: {e}")
        import traceback
        traceback.print_exc()
        
        return jsonify({
            'error': 'Erro na coleta APIFY',
            'message': str(e),
            'apify_mode': True
        }), 500

@app.route('/', methods=['GET'])
def root():
    """Endpoint raiz"""
    apify_token = os.environ.get('APIFY_API_TOKEN')
    apify_status = "‚úÖ CONFIGURADO" if apify_token else "‚ùå N√ÉO CONFIGURADO"
    
    return jsonify({
        'service': 'HELIO Job Robot API',
        'status': 'online',
        'mode': 'APIFY REAL',
        'apify_status': apify_status,
        'endpoints': [
            '/api/health',
            '/api/agent1/collect-keywords'
        ]
    })

if __name__ == '__main__':
    port = int(os.environ.get('PORT', 5000))
    logger.info(f"üöÄ Iniciando HELIO APIFY API na porta {port}")
    logger.info(f"üîë APIFY Token: {'‚úÖ CONFIGURADO' if os.environ.get('APIFY_API_TOKEN') else '‚ùå N√ÉO CONFIGURADO'}")
    app.run(host='0.0.0.0', port=port, debug=False) 